{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Support Vector Machines\n",
    "\n",
    "- [1, What are SVMs?](#what-are-svms)\n",
    "- [2. Primal approach - Hard-Margin SVM](#hard-margin-svm)\n",
    "- [(Optional) - Deriving the margin requirement](#margin-derivation)\n",
    "- [3. Primal approach - Soft-Margin SVM](#soft-margin-svm)\n",
    "- [4. Solving the primal optimization problem](#solving-primal-svm)\n",
    "   - [4.1 Hinge loss function](#hinge-loss)\n",
    "   - [4.2 Updated objective function](#updated-objective-function)\n",
    "   - [(Optional) Three parts of the objective function](#two-parts)\n",
    "   - [4.3 Subgradient descent](#subgradient-descent)\n",
    "   - [(Optional) Subgradient descent vs. gradient descent](#subgradient-descent-vs-gradient-descent)\n",
    "- [5. Implementation of primal approach](#primal-implementation)\n",
    "   - [5.1 Toy dataset](#toy-dataset)\n",
    "   - [5.2 SVM class](#primal-svm-class)\n",
    "   - [5.3 Training and testing an SVM](#train-test-svm)  \n",
    "   - [5.4 Visualizing the decision boundary](#decision-boundary)\n",
    "- [6. Dual approach](#dual-approach)\n",
    "    - [6.1 Recap Lagrange multipliers](#recap-lagrange-multipliers)\n",
    "    - [6.2 Recap Lagrangian](#recap-lagrangian)\n",
    "    - [6.3 Dual optimization problem](#dual-optimization-problem)\n",
    "- [7. Primal vs. dual approach](#primal-vs-dual)\n",
    "- [8. Kernels / non-linear SMVs](#kernel-svms)\n",
    "    - [8.1 What is a kernel?](#what-is-a-kernel)\n",
    "    - [8.2 What are kernels good for?](#what-are-kernels-good-for)\n",
    "    - [8.3 Example](#kernel-example)\n",
    "    - [8.4 Can we also use kernels in the primal SVM?](#kernel-in-primal-svm)\n",
    "- [9. Sources and further reading](#sources)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Link to interactive demo\n",
    "\n",
    "[Click here](https://mybinder.org/v2/gh/zotroneneis/machine_learning_basics/HEAD?filepath=support_vector_machines.ipynb) to run the notebook online (using Binder) without installing jupyter or downloading the code.\n",
    "\n",
    "Sometimes, the GitHub version of the Jupyter notebook does not display the math formulas correctly. Please refer to the Binder version in case you think something might be off or missing.\n",
    "\n",
    "I also wrote a [blog post containing the contents of the notebook](https://alpopkes.com/posts/machine_learning/support_vector_machines/)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. What are support vector machines? <a class=\"anchor\" id=\"what-are-svms\"></a>\n",
    "\n",
    "Support vector machines (short: SVMs) are supervised machine learning models. They are the most prominent member of the class of [*kernel methods*](https://en.wikipedia.org/wiki/Kernel_method). SVMs can be used both for classification and regression. The original SVM proposed in 1963 is a simple binary linear classifier. What does this mean?\n",
    "\n",
    "Assume we are given a dataset $D = \\big \\{ \\mathbf{x}_n, y_n \\big \\}_{n=1}^N$, where $\\mathbf{x} \\in \\mathbb{R}^D$ and labels $y_n \\in \\{-1, +1 \\}$. A linear (hard-margin) SVM separates the two classes using a ($D-1$ dimensional) hyperplane.\n",
    "\n",
    "Special to SVMs is that they use not any hyperplane but the one that maximizes the distance between itself and the two sets of datapoints. Such a hyperplane is called *maximum-margin* hyperplane:\n",
    "\n",
    "<img src=\"figures/separating_hyperplanes.png\" width=\"800\"/>\n",
    "\n",
    "In case you have never heard the term margin: the margin describes the distance between the hyperplane and the closest examples in the dataset.\n",
    "\n",
    "Two types of SVMs exist: primals SVMs and dual SVMs. Although most research in the past looked into dual SVMs both can be used to perform non-linear classification. Therefore, we will look at both approaches and compare them in the end."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Primal approach - Hard-margin SVM  <a class=\"anchor\" id=\"hard-margin-svm\"></a>\n",
    "\n",
    "When training an SVM our goal is to find the hyperplane that maximizes the margin between the two sets of points. This hyperplane is fully defined by the points closest to the margin, which are also called *support vectors*.\n",
    "\n",
    "The equation of a hyperplane is given by $\\langle \\mathbf{w}, \\mathbf{x} \\rangle + b = 0$. If an example $\\mathbf{x}_i$ lies on the right side of the hyperplane (that is, it has a positive label) we have $\\langle \\mathbf{w}, \\mathbf{x} \\rangle + b \\gt 0$. If instead $\\mathbf{x}_i$ lies on the left side (= negative label) we have $\\langle \\mathbf{w}, \\mathbf{x} \\rangle + b \\lt 0$.\n",
    "\n",
    "The support vectors lie exactly on the margin and the optimal separating hyperplane should have the same distance from all support vectors. In this sense the maximum margin hyperplane lies between two separating hyperplanes that are determined by the support vectors:\n",
    "\n",
    "<img src=\"figures/delimiting_hyperplanes.png\" width=\"450\"/>\n",
    "\n",
    "### Goal 1:\n",
    "When deriving a formal equation for the maximum margin hyperplane we assume that the two delimiting hyperplanes are given by:   \n",
    "$$\\langle \\mathbf{w}, \\mathbf{x}_{+} \\rangle + b = +1$$ \n",
    "$$\\langle \\mathbf{w}, \\mathbf{x}_{-} \\rangle + b = -1$$\n",
    "\n",
    "In other words: we want our datapoints two lie at least a distance of 1 away from the decision hyperplane into both directions. To be more precise: for our positive examples (those with label $y_n = +1$) we want the following to hold: $\\langle \\mathbf{w}, \\mathbf{x}_n \\rangle + b \\ge +1$.\n",
    "\n",
    "For our negative examples (those with label $y_n = -1$) we want the opposite: $\\langle \\mathbf{w}, \\mathbf{x}_n \\rangle + b \\le -1$. This can be combined into a single equation: $y_n(\\langle \\mathbf{w}, \\mathbf{x}_n \\rangle + b) \\ge 1$. This is our first goal: **We want a decision boundary that classifies our training examples correctly.**\n",
    "\n",
    "\n",
    "### Goal 2:\n",
    "Our second goal is to maximize the margin of this decision boundary. The margin is given by $\\frac{1}{\\mathbf{w}}$. If you would like to understand where this value is coming from take a look at the section \"*(Optional) Deriving the margin equation*\" below.\n",
    "\n",
    "Our goal to maximize the margin can be expressed as follows:\n",
    "$$ \\max_{\\mathbf{w}, b} \\frac{1}{\\Vert \\mathbf{w} \\Vert}$$\n",
    "\n",
    "Instead of maximizing $\\frac{1}{\\Vert \\mathbf{w} \\Vert}$ we can instead minimize $\\frac{1}{2} \\Vert \\mathbf{w} \\Vert^2$. This simplifies the computation of the gradient.\n",
    "\n",
    "### Combined goal\n",
    "Combining goal one and goal two yields the following objective function:   \n",
    "$$\n",
    "\\min_{\\mathbf{w}, b} \\frac{1}{2} \\Vert \\mathbf{w} \\Vert^2\n",
    "$$\n",
    "$$\n",
    "\\text{subject to: } y_n(\\langle \\mathbf{w}, \\mathbf{x}_n \\rangle + b) \\ge 1 \\text{ for all } n = 1, ..., N\n",
    "$$\n",
    "\n",
    "In words: we want to find the values for $\\mathbf{w}$ and $b$ that maximize the margin while classifying all training examples correctly. This approach is called the *hard-margin support vector machine*. \"Hard\" because it does not allow for violations of the margin requirement (= no points are allowed to be within the margin)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (Optional) Deriving the margin equation <a class=\"anchor\" id=\"margin-derivation\"></a>\n",
    "\n",
    "We can derive the width of the margin in several ways (see sections 12.2.1-12.2.2 of the [Mathematics for Machine Learning book](https://mml-book.com)). Personally, I found the explanation of [this MIT lecture on SVMs](https://www.youtube.com/watch?v=_PwhiWxHK8o) easiest to understand.\n",
    "\n",
    "The derivation of the margin is based on the assumptions that we have already noted above:\n",
    "$$\\langle \\mathbf{w}, \\mathbf{x}_{+} \\rangle + b = +1$$ \n",
    "$$\\langle \\mathbf{w}, \\mathbf{x}_{-} \\rangle + b = -1$$\n",
    "\n",
    "Including the label of each example we can rewrite this as \n",
    "$$y_i (\\langle \\mathbf{w}, \\mathbf{x}_{i} \\rangle + b) -1 = 0$$\n",
    "\n",
    "Let's say we have a positive example $\\mathbf{x}_{+}$ that lies on the right delimiting hyperplane and a negative example $\\mathbf{x}_{-}$ that lies on the left delimiting hyperplane. The distance between these two vectors is given by ($\\mathbf{x}_{+} - \\mathbf{x}_{-})$. We want to compute the orthogonal projection of the vector onto the line that is perpendicular to the decision hyperplane. This would give us the width between the two delimiting hyperplanes. We can compute this by multiplying the vector ($\\mathbf{x}_{+} - \\mathbf{x}_{-})$ with a vector that is perpendicular to the hyperplane. We know that the vector $\\mathbf{w}$ is perpendicular to the decision hyperplane. So we can compute the margin by multiplying $(\\mathbf{x}_{+} - \\mathbf{x}_{-})$ with the vector $\\mathbf{w}$ where the latter is divided by the scale $||\\mathbf{w}||$ to make it a unit vector.\n",
    "\n",
    "<img src=\"figures/maximum_margin_derivation.png\" width=\"500\"/>\n",
    "\n",
    "$$\n",
    "\\begin{align*}\n",
    "\\text{width} &= (\\mathbf{x}_{+} - \\mathbf{x}_{-}) \\cdot \\frac{\\mathbf{w}}{||\\mathbf{w}||} \\\\\n",
    "&= \\frac{\\mathbf{x}_{+} \\cdot \\mathbf{w}}{||\\mathbf{w}||} - \\frac{\\mathbf{x}_{-} \\cdot \\mathbf{w}}{||\\mathbf{w}||}\n",
    "\\end{align*}\n",
    "$$\n",
    "\n",
    "For the positive example $\\mathbf{x}_{+}$ we have $y_+ = +1$ and therefore $(\\langle \\mathbf{w}, \\mathbf{x}_{+} \\rangle = 1 - b$. For the negative example $\\mathbf{x}_{-}$ we have $y_- = -1$ and therefore $- (\\langle \\mathbf{w}, \\mathbf{x}_{-} \\rangle) = 1 + b$:\n",
    "\n",
    "$$\n",
    "\\begin{align*}\n",
    "\\text{width} &= (\\mathbf{x}_{+} - \\mathbf{x}_{-}) \\cdot \\frac{\\mathbf{w}}{||\\mathbf{w}||} \\\\\n",
    "&= \\frac{\\mathbf{x}_{+} \\cdot \\mathbf{w}}{||\\mathbf{w}||} - \\frac{\\mathbf{x}_{-} \\cdot \\mathbf{w}}{||\\mathbf{w}||} \\\\ \n",
    "&= \\frac{(1 - b) + (1 + b)}{||\\mathbf{w}||}\\\\ \n",
    "&= \\frac{2}{||\\mathbf{w}||}\\\\ \n",
    "\\end{align*}\n",
    "$$\n",
    "\n",
    "We conclude that the width between the two delimiting hyperplanes equals $\\frac{2}{\\mathbf{w}}$. And therefore, that the distance between the decision hyperplane and each delimiting hyperplane is $\\frac{1}{\\mathbf{w}}$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  3. Primal approach - Soft-margin SVM <a class=\"anchor\" id=\"soft-margin-svm\"></a>\n",
    "\n",
    "In most real-world situations the available data is not linearly separable. Even if it is, we might prefer a solution which separates the data well while ignoring some noisy examples and outliers. This motivated an extension of the original hard-margin SVM called *soft-margin SVM*.\n",
    "\n",
    "A soft-margin SVM allows for violations of the margin requirement (= classification errors). In other words: not all training examples need to be perfectly classified. They might fall within the margin or even lie on the wrong side of the decision hyperplane. However, such violations are not for free. We pay a cost for each violation, where the value of the cost depends on how far the example is from meeting the margin requirement.\n",
    "\n",
    "To implement this we introduce so called *slack variables* $\\xi_n$. Each training example $(\\mathbf{x}_n, y_n)$ is assigned a slack variable $\\xi_n \\ge 0$. The slack variable allows this example to be within the margin or even on the wrong side of the decision hyperplane:\n",
    "\n",
    "- If $\\xi_n = 0$ the training example $(\\mathbf{x}_n, y_n)$ lies exactly on the margin\n",
    "- $0 \\lt \\xi_n \\lt 1$ the training example lies within the margin but on the correct side of the decision hyperplane\n",
    "- $\\xi_n \\ge 1$ the training example lies on the wrong side of the decision hyperplane\n",
    "    \n",
    "We extend our objective function to include the slack variables as follows:\n",
    "$$ \\min_{\\mathbf{w}, b, \\mathbf{\\xi}} \\frac{1}{2} \\Vert \\mathbf{w} \\Vert^2 + C \\sum_{n=1}^N \\xi_n $$\n",
    "\n",
    "$$ \\text{subject to:} $$\n",
    "\n",
    "$$ \\begin{equation}\n",
    "y_n(\\langle \\mathbf{w}, \\mathbf{x}_n \\rangle + b) \\ge 1 - \\xi_n\n",
    "\\end{equation}$$\n",
    "\n",
    "$$ \\xi_i \\gt 0 \\text{ for all } n = 1, ..., N $$\n",
    "\n",
    "Note: the objective function is somewhat not displayed correctly within the GitHub version of the notebook. It should look as follows:\n",
    "\n",
    "<img src=\"figures/primal_optimization_problem.png\" width=\"220\"/>\n",
    "\n",
    "The parameter $C$ is a regularization term that controls the trade-off between maximizing the margin and minimizing the training error (which in turn means classifying all training examples correctly). If the value of $C$ is small, we care more about maximizing the margin than classifying all points correctly. If the value of $C$ is large, we care more about classifying all points correctly than maximizing the margin."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Solving the primal optimization problem <a class=\"anchor\" id=\"solving-primal-svm\"></a>\n",
    "\n",
    "Theoretically, the primal SVM can be solved in multiple ways. The most well known way is to use the [hinge loss function](https://en.wikipedia.org/wiki/Hinge_loss) together with [subgradient descent](https://en.wikipedia.org/wiki/Subgradient_method).\n",
    "\n",
    "### 4.1 Hinge loss function <a class=\"anchor\" id=\"hinge-loss\"></a>\n",
    "The hinge loss function given the true target $y \\in \\{-1, +1\\}$ and the prediction $f(\\mathbf{x}) = \\langle\\mathbf{w}, \\mathbf{x}\\rangle+b$ is computed as follows:\n",
    "\n",
    "$$\\ell(t)=\\max \\{0,1-t\\} \\quad \\text{where} \\quad t=y \\cdot f(\\mathbf{x})= y \\cdot \\big(\\langle\\mathbf{w}, \\mathbf{x}\\rangle+b\\big)$$\n",
    "\n",
    "Let's understand the output of this loss function with a few examples:\n",
    "- If a training example has label $y = -1$ and the prediction is on the correct side of the marghin (that is, $f(\\mathbf{x}) \\le -1$), the value of $t$ is larger or equal to $+1$. Therefore, the hinge loss will be zero ($\\ell(t) = 0$)\n",
    "- The same holds if a training example has label $y = 1$ and the prediction is on the correct side of the margin (that is, $f(\\mathbf{x}) \\ge 1$)\n",
    "- If a training example ($y = 1$) is on the correct side of the decision hyperplane but lies within the margin (that is, $0 \\lt f(\\mathbf{x}) \\lt 1$) the hinge loss will output a positive value.\n",
    "- If a training example ($y = 1$) is on the wrong side of the decision hyperplane (that is, $f(\\mathbf{x}) \\lt 0$), the hinge loss returns an even larger value. This value increases linearly with the distance from the decision hyperplane\n",
    "\n",
    "<img src=\"figures/hinge_loss.png\" width=\"600\"/>\n",
    "\n",
    "\n",
    "### 4.2 Updated objective function <a class=\"anchor\" id=\"updated-objective-function\"></a>\n",
    "\n",
    "Using the hinge loss we can reformulate the optimization problem of the primal soft-margin SVM. Given a dataset $D = \\big \\{ \\mathbf{x}_n, y_n \\big \\}_{n=1}^N$ we would like to minimize the total loss which is now given by:\n",
    "\n",
    "$$\n",
    "\\min _{\\mathbf{w}, b} \\frac{1}{2}\\|\\mathbf{w}\\|^{2} + C \\sum_{n=1}^{N} \\max \\left\\{0,1-y_{n}\\left(\\left\\langle\\mathbf{w}, \\mathbf{x}_{n}\\right\\rangle+b\\right)\\right\\}\n",
    "$$\n",
    "\n",
    "If you would like to understand why this is equivalent to our previous formulation of the soft-margin SVM please take a look at chapter 12.2.5 of the [Mathematics for Machine Learning book](https://mml-book.com)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [Optional] Three parts of the objective function <a class=\"anchor\" id=\"two-parts\"></a>\n",
    "\n",
    "Our objective function can be divided into three distinct parts:\n",
    "\n",
    "Part 1: $\\frac{1}{2}\\|\\mathbf{w}\\|^{2}$\n",
    "\n",
    "This part is also called the *regularization term*. It expresses a preference for solutions that separate the datapoints well, thereby maximizing the margin. In theory, we could replace this term by a different regularization term that expresses a different preference.\n",
    "\n",
    "Part 2: $\\sum_{n=1}^{N} \\max \\left\\{0,1-y_{n}\\left(\\left\\langle\\mathbf{w}, \\mathbf{x}_{n}\\right\\rangle+b\\right)\\right\\}$\n",
    "\n",
    "This part is also called the *empirical loss*. In our case it's the hinge loss which penalizes solutions that make mistakes when classifying the training examples. In theory, this term could be replaced with another loss function that expresses a different preference.\n",
    "\n",
    "Part 3: The hyperparameter $C$ that controls the tradeoff between a large margin and a small hinge loss."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3 Sub-gradient descent <a class=\"anchor\" id=\"subgradient-descent\"></a>\n",
    "\n",
    "The hinge loss function is not differentiable (namely at the point $t=1$). Therefore, we cannot compute the gradient right away. However, we can use a method called [subgradient descent](https://en.wikipedia.org/wiki/Subgradient_method) to solve our optimization problem. To simplify the derivation we will adapt two things:\n",
    "1. We assume that the bias $b$ is contained in our weight vector as the first entry $w_0$, that is $\\mathbf{w} = [b, w_1, ..., w_D]$\n",
    "2. We divide the hinge loss by the number of samples\n",
    "\n",
    "Our cost function is then given by \n",
    "$$\n",
    "J(\\mathbf{w}) = \\frac{1}{2}\\|\\mathbf{w}\\|^{2} + C \\frac{1}{N} \\sum_{n=1}^{N} \\max \\left\\{0,1-y_{n}\\left(\\left\\langle\\mathbf{w}, \\mathbf{x}_{n}\\right\\rangle\\right)\\right\\}\n",
    "$$\n",
    "\n",
    "We will reformulate this to simplify computing the gradient:\n",
    "$$\n",
    "J(\\mathbf{w}) = \\frac{1}{N} \\sum_{n=1}^{N} \\Big[ \\frac{1}{2}\\|\\mathbf{w}\\|^{2} + C \\max \\left\\{0,1-y_{n}\\left(\\left\\langle\\mathbf{w}, \\mathbf{x}_{n}\\right\\rangle\\right)\\right\\}\\Big]\n",
    "$$\n",
    "\n",
    "\n",
    "The gradient is given by:\n",
    "$$\n",
    "\\nabla_{w} J(\\mathbf{w}) = \\frac{1}{N} \\sum_{n=1}^N \\left\\{\\begin{array}{ll}\n",
    "\\mathbf{w} & \\text{if} \\max \\left(0,1-y_{n} \\left(\\langle \\mathbf{w}, \\mathbf{x}_{n} \\rangle \\right)\\right)=0 \\\\\n",
    "\\mathbf{w}-C  y_{n} \\mathbf{x}_{n} & \\text { otherwise }\n",
    "\\end{array}\\right.\n",
    "$$\n",
    "\n",
    "With this formula we can apply stochastic gradient descent to solve the optimization problem."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [Optional] Difference subgradient descent and gradient descent <a class=\"anchor\" id=\"subgradient-descent=vs-gradient-descent\"></a>\n",
    "\n",
    "The subgradient method allows us to minimize a non-differentiable convex function. Although looking similar to gradient descent the method has several important differences.\n",
    "\n",
    "#### What is a subgradient?\n",
    "\n",
    "A subgradient can be described as a generalization of gradients to non-differentiable functions. Informally, a sub-tangent at a point is any line that lies below the function at the point. The subgradient is the slope of this line. Formally, the subgradient a convex function $f$ at $w_0$ is defined as all vectors $g$ such that for any other point $w$\n",
    "\n",
    "$$ f(w) - f(w_0) \\ge g \\cdot (w - w_0) $$\n",
    "\n",
    "If $f$ is differentiable at $w_0$, the subgradient contains only one vector which equals the gradient $\\nabla f(w_0)$. If, however, $f$ is not differentiable, there may be several values for $g$ that satisfy this inequality. This is illustrated in the figure below.\n",
    "\n",
    "<img src=\"figures/gradient_vs_subgradient.png\" width=\"900\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Subgradient method\n",
    "\n",
    "To minimize the objective function $f$ the subgradient method uses the following update formula for iteration $k+1$:\n",
    "\n",
    "$$ w^{(k+1)} = w^{(k)} - \\alpha_k g^{(k)}$$ \n",
    "\n",
    "Where $g^{(k)}$ is *any* subgradient of $f$ at $w^{(k)}$ and $\\alpha_k$ is the $k$-th step size. Thus, at each iteration, we make a step into the direction of the negative subgradient. When $f$ is differentiable, $g^{(k)}$ equals the gradient $\\nabla f(x^{(k)})$ and the method reduces to the standard gradient descent method.\n",
    "\n",
    "More details on the subgradient method can be found [here](https://web.stanford.edu/class/ee392o/subgrad_method.pdf)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Implementation primal approach <a class=\"anchor\" id=\"primal-implementation\"></a>\n",
    "\n",
    "### 5.1 Toy dataset <a class=\"anchor\" id=\"toy-dataset\"></a>\n",
    "To implement what we have learned about primal SVMs we first have to generate a dataset. In the cell below we create a simple dataset with two features and labels +1 and -1. We further split the dataset into a test and train set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.datasets import make_blobs\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "features, targets = make_blobs(n_samples=600, centers=2, n_features=2, random_state=42)\n",
    "\n",
    "# The function outputs targets 0 and 1 so we need to convert targets 0 to -1\n",
    "transformed_targets = [-1 if t == 0 else +1 for t in targets]\n",
    "        \n",
    "# Plot the dataset\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.scatter(features[:, 0], features[:, 1], c = transformed_targets)\n",
    "plt.title(\"Toy dataset\")\n",
    "plt.ylabel(\"Feature 2\")\n",
    "plt.xlabel(\"Feature 1\")\n",
    "plt.show()\n",
    "\n",
    "# Split data into training and test set\n",
    "features_train, features_test, labels_train, labels_test = train_test_split(features, \n",
    "                                                                              transformed_targets, \n",
    "                                                                              test_size = 0.3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.2 SVM class definition <a class=\"anchor\" id=\"primal-svm-class\"></a>\n",
    "\n",
    "Next, we would like to implement an SVM class. We will use the knowledge we already acquired:\n",
    "\n",
    "1. Our objective function using the hinge loss function is given by: \n",
    "$$\n",
    "J(\\mathbf{w}) = \\frac{1}{2}\\|\\mathbf{w}\\|^{2} + C \\frac{1}{N} \\sum_{n=1}^{N} \\max \\left\\{0,1-y_{n}\\left(\\left\\langle\\mathbf{w}, \\mathbf{x}_{n}\\right\\rangle\\right)\\right\\}\n",
    "$$\n",
    "2. We can minimize this function by computing the gradient: \n",
    "$$\n",
    "\\nabla_{w} J(\\mathbf{w}) = \\frac{1}{N} \\sum_{n=1}^N \\left\\{\\begin{array}{ll}\n",
    "\\mathbf{w} & \\text{if} \\max \\left(0,1-y_{n} \\left(\\langle \\mathbf{w}, \\mathbf{x}_{n} \\rangle \\right)\\right)=0 \\\\\n",
    "\\mathbf{w}-C  y_{n} \\mathbf{x}_{n} & \\text { otherwise }\n",
    "\\end{array}\\right.\n",
    "$$\n",
    "3. Given the gradient we use stochastic gradient descent to train our model\n",
    "4. After training our model we can make predictions using the [sign function](https://en.wikipedia.org/wiki/Sign_function)\n",
    "\n",
    "As mentioned previously, we will assume that the bias $b$ is contained in our weight vector as the first entry $w_0$, that is $\\mathbf{w} = [b, w_1, ..., w_D] = \\mathbf{w} = [w_0, w_1, ..., w_D]$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "class LinearSVM:\n",
    "    \n",
    "    def __init__(self, regularization_param):\n",
    "        \"\"\"\n",
    "        Initialize the model by setting the regularization parameter \n",
    "        and a boolean variable for our trained weights.\n",
    "        \"\"\"\n",
    "        self.regularization_param = regularization_param\n",
    "        self.trained_weights = None\n",
    "    \n",
    "    def add_bias_term(self, features):\n",
    "        \"\"\"\n",
    "        Add intercept 1 to each training example for bias b\n",
    "        \"\"\"\n",
    "        n_samples = features.shape[0]\n",
    "        ones = np.ones((n_samples, 1))\n",
    "        return np.concatenate((ones, features), axis=1)\n",
    "    \n",
    "    def compute_cost(self, weights, features, labels) -> float:\n",
    "        \"\"\"\n",
    "        Compute the value of the cost function\n",
    "        \"\"\"\n",
    "        n_samples = features.shape[0]\n",
    "        \n",
    "        # Compute hinge loss \n",
    "        predictions = np.dot(features, weights).flatten()\n",
    "        distances = 1 - labels * predictions\n",
    "        hinge_losses = np.maximum(0, distances)\n",
    "\n",
    "        # Compute sum of the individual hinge losses\n",
    "        sum_hinge_loss = np.sum(hinge_losses) / n_samples\n",
    "\n",
    "        # Compute entire cost\n",
    "        cost = (1 / 2) * np.dot(weights.T, weights) + self.regularization_param * sum_hinge_loss\n",
    "        \n",
    "        return float(cost)\n",
    "    \n",
    "    def compute_gradient(self, weights, features, labels) -> np.ndarray:\n",
    "        \"\"\"\n",
    "        Compute the gradient, needed for training\n",
    "        \"\"\"\n",
    "        predictions = np.dot(features, weights)\n",
    "        distances = 1 - labels * predictions\n",
    "        n_samples, n_feat = features.shape\n",
    "        sub_gradients = np.zeros((1, n_feat))\n",
    "\n",
    "        for idx, dist in enumerate(distances):\n",
    "            if max(0, dist) == 0:\n",
    "                sub_gradients += weights.T\n",
    "            else:\n",
    "                sub_grad = weights.T - (self.regularization_param * features[idx] * labels[idx])\n",
    "                sub_gradients += sub_grad\n",
    "                            \n",
    "        # Sum up and divide by the number of samples\n",
    "        avg_gradient = sum(sub_gradients) / len(labels)\n",
    "\n",
    "        return avg_gradient\n",
    "    \n",
    "    def train(self, train_features, train_labels, n_epochs, learning_rate=0.01, batch_size=1):\n",
    "        \"\"\"\n",
    "        Train the model with stochastic gradient descent using the\n",
    "        specified number of epochs, learning rate and batch size.\n",
    "        \"\"\"\n",
    "        # Add bias term to features\n",
    "        train_features = self.add_bias_term(train_features)\n",
    "        \n",
    "        # Initalize weight vector\n",
    "        n_samples, n_feat = train_features.shape\n",
    "        weights = np.zeros(n_feat)[:, np.newaxis]\n",
    "        \n",
    "        # Train the model for a certain number of epochs\n",
    "        for epoch in range(n_epochs):\n",
    "            features, labels = shuffle(train_features, train_labels)\n",
    "            features, labels = train_features, train_labels\n",
    "            start, end = 0, batch_size\n",
    "            while end <= len(labels): # Training loop over the dataset\n",
    "                batch = features[start:end]\n",
    "                batch_labels = labels[start:end]\n",
    "                \n",
    "                grad = self.compute_gradient(weights, batch, batch_labels)\n",
    "                update = (learning_rate * grad)[:, np.newaxis]\n",
    "                weights = weights - update\n",
    "                start, end = end, end + batch_size\n",
    "                \n",
    "            current_cost = self.compute_cost(weights, features, labels)\n",
    "            print(f\"Epoch {epoch + 1}, cost: {current_cost}\")\n",
    "                \n",
    "        # Set the trained weights to allow making predictions\n",
    "        self.trained_weights = weights\n",
    "\n",
    "    def predict(self, test_features) -> np.ndarray:\n",
    "        \"\"\"\n",
    "        Predict labels for new test features.\n",
    "        Raises ValueError if model has not been trained yet.\n",
    "        \"\"\"\n",
    "        test_features = self.add_bias_term(test_features)\n",
    "        if self.trained_weights is None:\n",
    "            raise ValueError(\"You haven't trained the SVM yet!\")\n",
    "            \n",
    "        predicted_labels = []\n",
    "        n_samples = test_features.shape[0]\n",
    "        for idx in range(n_samples):\n",
    "            prediction = np.sign(np.dot(self.trained_weights.T, test_features[idx]))\n",
    "            predicted_labels.append(prediction)\n",
    "            \n",
    "        return np.array(predicted_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute some values to make sure the cost is computed correctly\n",
    "# I calculated the values for this example by hand first\n",
    "svm = LinearSVM(regularization_param=1)\n",
    "weights = np.array([1, 2])[:, np.newaxis]\n",
    "features = np.array([[0.5], [2.5]])\n",
    "new_features = svm.add_bias_term(features)\n",
    "\n",
    "labels = np.array([-1, +1])\n",
    "assert svm.compute_cost(weights, new_features, labels) == 4.\n",
    "gradient = svm.compute_gradient(weights, new_features, labels[:, np.newaxis])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.3 Training and testing an SVM <a class=\"anchor\" id=\"train-test-svm\"></a>\n",
    "\n",
    "After defining our SVM class we can train a model and test it on unseen examples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, cost: 27.993059232575494\n",
      "Epoch 2, cost: 8.038215480422444\n",
      "Epoch 3, cost: 3.428421715635218\n",
      "Epoch 4, cost: 2.2536479034033543\n",
      "Epoch 5, cost: 1.8533494983568986\n",
      "Epoch 6, cost: 1.590022103673107\n",
      "Epoch 7, cost: 1.4247146081301103\n",
      "Epoch 8, cost: 1.301007128477351\n",
      "Epoch 9, cost: 1.2027675603456405\n",
      "Epoch 10, cost: 1.1411244858178704\n"
     ]
    }
   ],
   "source": [
    "# Initialize a new SVM and train it on the given toy dataset\n",
    "regularization_param = 100\n",
    "lr = 0.000001\n",
    "svm = LinearSVM(regularization_param)\n",
    "trained_weights = svm.train(features_train, labels_train, n_epochs=10, learning_rate=lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on test dataset: 1.0\n",
      "Recall on test dataset: 1.0\n",
      "Precision on test dataset: 1.0\n"
     ]
    }
   ],
   "source": [
    "# Predict lables for unknown test samples\n",
    "from sklearn.metrics import accuracy_score, recall_score, precision_score\n",
    "\n",
    "predicted_labels = svm.predict(features_test)\n",
    "predicted_labels = predicted_labels.flatten()\n",
    "\n",
    "print(\"Accuracy on test dataset: {}\".format(accuracy_score(labels_test, predicted_labels)))\n",
    "print(\"Recall on test dataset: {}\".format(recall_score(labels_test, predicted_labels)))\n",
    "print(\"Precision on test dataset: {}\".format(precision_score(labels_test, predicted_labels)))    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.4 Visualizing the decision boundary <a class=\"anchor\" id=\"decision-boundary\"></a>\n",
    "\n",
    "Given our trained model we can visualize the decision boundary, as done below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 504x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Create dataset for visualization\n",
    "size=40000\n",
    "feat_1 = np.random.uniform(low=-6, high=7, size=size)\n",
    "feat_2 = np.random.uniform(low=-1, high=13, size=size)\n",
    "features_vis = np.column_stack((feat_1, feat_2))\n",
    "\n",
    "labels_vis = svm.predict(features_vis)\n",
    "\n",
    "# Plot the decision boundary\n",
    "plt.figure(figsize=(7, 5))\n",
    "plt.scatter(features_vis[:, 0], features_vis[:, 1], c = labels_vis)\n",
    "plt.title(\"SVM decision boundary\")\n",
    "plt.ylabel(\"Feature 2\")\n",
    "plt.xlabel(\"Feature 1\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Dual approach <a class=\"anchor\" id=\"dual-approach\"></a>\n",
    "\n",
    "In the previous sections we took a detailed look at the primal SVM. To solve a primal SVM, we need to find the best values for the weights and bias. Recall that our input examples $\\mathbf{x} \\in \\mathbb{R}^D$ have $D$ features. Consequently, our weights $\\mathbf{w}$ have $D$ features, too. This can become problematic if the number of features $D$ is large.\n",
    "\n",
    "That's where the second way of formalizing SVMs (called *dual approach*) comes in handy. The optimization problem of the dual approach is independent of the number of features. Instead, the number of parameters increases with the number of examples in the training set. \n",
    "\n",
    "The dual approach uses the method of Lagrange multipliers. Lagrange multipliers allow us to find the minimum or maximum of a function if there are one or more constraints on the input values we are allowed to used.\n",
    "\n",
    "If you never heard of Lagrange multipliers I can recommend the [blog posts](https://www.khanacademy.org/math/multivariable-calculus/applications-of-multivariable-derivatives/constrained-optimization/a/lagrange-multipliers-single-constraint) and [video tutorials](https://www.youtube.com/watch?v=yuqB-d5MjZA&list=PLCg2-CTYVrQvNGLbd-FN70UxWZSeKP4wV&index=1) on the topic from Khan Academy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.1 Recap Lagrange multipliers <a class=\"anchor\" id=\"recap-lagrange-multipliers\"></a>\n",
    "\n",
    "Lagrange multipliers allow us to solve constrained optimization problems. Let's say we want to maximize the function $f(x, y) = 2x + y$ under the constraint that our values of $x$ and $y$ satisfy the following equation: $g(x, y) = x^2 + y^2 = 1$. This constraint equation describes a circle of radius 1. \n",
    "\n",
    "The key insight behind the solution to this problem is that we need to find those values for $x$ and $y$ where the gradients of $f$ and $g$ are aligned. This can be expressed using a Lagrange multiplier (typically $\\lambda$):\n",
    "\n",
    "We want to find those values $x_m, y_m$ where $\\nabla f(x_m, y_m) = \\lambda \\nabla g(x_m, y_m)$.\n",
    "\n",
    "In our example the gradient vectors look as follows:\n",
    "$$ \\nabla f(x, y)=\\left[\\begin{array}{c}\n",
    "\\frac{\\partial}{\\partial x}(2 x+y) \\\\\n",
    "\\frac{\\partial}{\\partial y}(2 x+y)\n",
    "\\end{array}\\right]=\\left[\\begin{array}{c}\n",
    "2 \\\\ 1\n",
    "\\end{array}\\right]$$\n",
    " \n",
    "$$ \\nabla g(x, y)=\\left[\\begin{array}{c}\n",
    "\\frac{\\partial}{\\partial x}\\left(x^{2}+y^{2}-1\\right) \\\\\n",
    "\\frac{\\partial}{\\partial y}\\left(x^{2}+y^{2}-1\\right)\n",
    "\\end{array}\\right]=\\left[\\begin{array}{c}\n",
    "2 x \\\\ 2 y\n",
    "\\end{array}\\right]$$\n",
    "\n",
    "Therefore, the tangency condition results in \n",
    "$$ \\left[\\begin{array}{l}\n",
    "2 \\\\ 1\n",
    "\\end{array}\\right]=\\lambda \\left[\\begin{array}{l}\n",
    "2 x_{m} \\\\ 2 y_{m}\n",
    "\\end{array}\\right] $$\n",
    "\n",
    "We can rewrite the vector form into individual equations that can be solved by hand:\n",
    "- $2 = \\lambda 2 x_m $    \n",
    "- $1 = \\lambda 2 y_m $    \n",
    "- $x_m^2 + y_m^2 = 1 $\n",
    "\n",
    "Solving the equations yields \n",
    "$$ \\begin{aligned}\n",
    "\\left(x_{0}, y_{0}\\right) &=\\left(\\frac{1}{\\lambda_{0}}, \\frac{1}{2 \\lambda_{0}}\\right) \\\\\n",
    "&=\\left(\\frac{2}{\\sqrt{5}}, \\frac{1}{\\sqrt{5}}\\right) \\quad \\text { or } \\quad\\left(\\frac{-2}{\\sqrt{5}}, \\frac{-1}{\\sqrt{5}}\\right)\n",
    "\\end{aligned} $$\n",
    "\n",
    "where the first point denotes a maximum (what we wanted to find) and the second a minimum. This solves our constrained optimization problem. For more details and a full solution look at [this Khan academy post](https://www.khanacademy.org/math/multivariable-calculus/applications-of-multivariable-derivatives/constrained-optimization/a/lagrange-multipliers-single-constraint)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.2 Recap Lagrangian  <a class=\"anchor\" id=\"recap-lagrangian\"></a>\n",
    "\n",
    "The Lagrangian is a way to repackage the individual conditions of our constrained optimization problem into a single equation. In the example above we wanted to optimize some function $f(x, y)$ under the constraint that the inputs $x$ and $y$ satisfy the equation $g(x, y) = x^2 + y^2 = c$. In our case the constant $c$ was given by 1. We know that the solution is given by those points where the gradients of $f$ and $g$ align. The Lagrangian function puts all of this into a single equation:\n",
    "\n",
    "$$ \\mathcal{L}(x, y, \\lambda)=f(x, y)-\\lambda(g(x, y)-c) $$\n",
    "\n",
    "When computing the partial derivatives of $\\mathcal{L}$ with respect to $x, y$ and $\\lambda$ and setting them to zero, we will find that they correspond exactly to the three constraints we looked at earlier. This can be summarized by simply setting the gradient of $\\mathcal{L}$ equal to the zero vector: $\\nabla \\mathcal{L} = \\mathbf{0}$. The compact Lagrangian form is often used when solving constrained optimization problem with computers because it summarizes the elaborate problem with multiple constraints into a single equation. For more details and a full solution look at [this Khan academy post](https://www.khanacademy.org/math/multivariable-calculus/applications-of-multivariable-derivatives/constrained-optimization/a/lagrange-multipliers-single-constraint)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.3 Dual optimization problem   <a class=\"anchor\" id=\"dual-optimization-problem\"></a>\n",
    "For the primal soft-margin SVM we considered the following optimization problem: \n",
    "$$ \\min_{\\mathbf{w}, b, \\mathbf{\\xi}} \\frac{1}{2} \\Vert \\mathbf{w} \\Vert^2 + C \\sum_{n=1}^N \\xi_n $$\n",
    "\n",
    "$$ \\text{subject to:} $$\n",
    "\n",
    "$$ y_n(\\langle \\mathbf{w}, \\mathbf{x}_n \\rangle + b) \\ge 1 - \\xi_n $$\n",
    "\n",
    "$$ \\xi_i \\gt 0 \\text{ for all } n = 1, ..., N $$\n",
    "\n",
    "Note: the optimization problem is somewhat not displayed correctly within the GitHub version of the notebook. It should look as follows:\n",
    "\n",
    "<img src=\"figures/primal_optimization_problem.png\" width=\"220\"/>\n",
    "\n",
    "To derive the corresponding Lagrangian we will introduce two Lagrange multipliers: $\\alpha_n$ for the first constraint (that all examples are classified correctly) and $\\lambda_n$ for the second constraint (non-negativity of the slack variables). The Lagrangian is then given by:\n",
    "\n",
    "$$\n",
    "\\begin{aligned}\n",
    "\\mathfrak{L}(\\boldsymbol{w}, b, \\xi, \\alpha, \\gamma)=& \\frac{1}{2}\\|\\boldsymbol{w}\\|^{2}+C \\sum_{n=1}^{N} \\xi_{n} \\\\\n",
    "& \\underbrace{-\\sum_{n=1}^{N} \\alpha_{n}\\left(y_{n}\\left(\\left\\langle\\boldsymbol{w}, \\boldsymbol{x}_{n}\\right\\rangle+b\\right)-1+\\xi_{n}\\right)}_{\\text{first constraint}} \\underbrace{-\\sum_{n=1}^{N} \\gamma_{n} \\xi_{n}}_{\\text{second constraint}}\n",
    "\\end{aligned}\n",
    "$$\n",
    "\n",
    "Next, we have to compute the partial derivatives of the Lagrangian with respect to the variables $\\mathbf{w}, b$ and $\\xi$: $\\frac{\\partial \\mathfrak{L}}{\\partial \\mathbf{w}}, \\frac{\\partial \\mathfrak{L}}{\\partial b}, \\frac{\\partial \\mathfrak{L}}{\\partial \\xi}$. When setting the first partial derivative to zero we obtain an important interim result: \n",
    "$$ \\mathbf{w} = \\sum_{n=1}^N \\alpha_n y_n \\mathbf{x}_n $$\n",
    "\n",
    "This equation states the the optimal solution for the weight vector is given by a linear combination of our training examples. After setting the other partial derivatives to zero, using the result and simplifying the equations we end up with the following optimization problem (for details see section 12.3.1 of the [Mathematics for Machine Learning book](https://mml-book.com)):\n",
    "\n",
    "$$\\min _{\\boldsymbol{\\alpha}} \\frac{1}{2} \\sum_{i=1}^{N} \\sum_{j=1}^{N} y_{i} y_{j} \\alpha_{i} \\alpha_{j}\\left\\langle\\mathbf{x}_{i}, \\mathbf{x}_{j}\\right\\rangle-\\sum_{i=1}^{N} \\alpha_{i}$$\n",
    "$$ \\text{subject to:} $$\n",
    "$$\\sum_{i=1}^{N} y_{i} \\alpha_{i}=0$$\n",
    "$$0 \\le \\alpha_{i} \\le C \\text{ for all } i=1, \\ldots, N$$\n",
    "\n",
    "Note: the optimization problem is somewhat not displayed correctly within the GitHub version of the notebook. It should look as follows:\n",
    "\n",
    "<img src=\"figures/dual_optimization_problem.png\" width=\"270\"/>\n",
    "\n",
    "This constrained quadratic optimization problem can be solved very efficiently, for example with quadratic programming techniques. One popular library for solving dual SVMs is [libsvm](https://github.com/cjlin1/libsvm) which makes use of a decomposition method to solve the problem (see [this paper](https://www.csie.ntu.edu.tw/~cjlin/papers/libsvm.pdf) for more details). However, several other approaches exist."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Primal vs. dual approach <a class=\"anchor\" id=\"primal-vs-dual\"></a>\n",
    "\n",
    "Most SVM research in the last decade has been about the dual formulation. Why this is the case is not clear. Both approaches have advantages and disadvantages. In the paper [\"Training a Support Vector Machine in the Primal\"](https://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.129.3368&rep=rep1&type=pdf) Chapelle et al. mention the following hypothesis: \n",
    "\n",
    "> We believe that it is because SVMs were first introduced in their hard margin formulation (Boser et al., 1992), for which a dual optimization (because of the constraints) seems more natural. In general, however, soft margin SVMs should be preferred, even if the training data are separable: the decision boundary is more robust because more training points are taken into account (Chapelle et al., 2000). We do not pretend that primal optimization is better in general; our main motivation wasto point out that primal and dual are two sides of the same coin and that there is no reason to look always at the same side."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Kernels / non-linear SVM <a class=\"anchor\" id=\"kernel-svms\"></a>\n",
    "\n",
    "### 8.1 What is a kernel? <a class=\"anchor\" id=\"what-is-a-kernel\"></a>\n",
    "If you take another look at the optimization equation of dual SVMs you will notice that it computes the inner product $\\left\\langle\\mathbf{x}_{i}, \\mathbf{x}_{j}\\right\\rangle$ between all datapoints $\\mathbf{x}_{i}, \\mathbf{x}_{j}$. A kernel is a way to compute this inner product implicitely in some (potentially very high dimensional) feature space. To be more precise: assume we have some mapping function $\\varphi$ which maps an $n$ dimensional input vector to an $m$ dimensional output vector: $\\varphi \\, : \\, \\mathbb R^n \\to \\mathbb R^m$. Given this mapping function we can compute the dot product of two vectors $\\mathbf x$ and $\\mathbf y$ in this space as follows: $\\varphi(\\mathbf x)^T \\varphi(\\mathbf y)$.\n",
    "\n",
    "A kernel is a function $k$ that gives the same result as this dot product: $k(\\mathbf x, \\mathbf y) = \\varphi(\\mathbf x)^T \\varphi(\\mathbf y)$. In other words: the kernel function is equivalent to the dot product of the mapping function."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8.2 What are kernels good for? <a class=\"anchor\" id=\"what-are-kernels-good-for\"></a>\n",
    "\n",
    "Until now (apart from the soft-margin SVM) our SVMs, both primal and dual, are only able to classify data that is [linearly separable](https://en.wikipedia.org/wiki/Linear_separability). However, most datasets in practice won't be of this form. We need a way to classify data that is **not** linearly separable. This is where the so called **kernel trick** comes into play.\n",
    "\n",
    "Because the objective function of the dual SVM contains inner products only between datapoints $\\mathbf{x}_i, \\mathbf{x}_j$, we can easily replace this inner product (that is, $\\left\\langle\\mathbf{x}_{i}, \\mathbf{x}_{j}\\right\\rangle$ ) with some mapping function $\\varphi(\\mathbf{x}_i)^T \\varphi(\\mathbf{x}_j)$. This mapping function can be non-linear, allowing us to compute an SVM that is non-linear with respect to the input examples. The mapping function takes our input data (which is not linearly separable) and transforms it into some higher-dimensional space where it becomes linearly separable. This is illustrated in the figure below.\n",
    "\n",
    "<img src=\"figures/feature_mapping_illustration.png\" width=\"700\"/>\n",
    "\n",
    "In theory, we could use any mapping function we like. In practice, however, computing inner products is expensive. Therefore, we use mapping functions that have a corresponding kernel function. This will allow us to map the datapoints into a higher dimensional space without ever explicitely computing the (expensive) inner products.\n",
    "\n",
    "Let's take a look at an example. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8.3 Example <a class=\"anchor\" id=\"kernel-example\"></a>\n",
    "Note: this example was taken from [this StackExchange post](https://stats.stackexchange.com/posts/153134).\n",
    "\n",
    "We can create a simple polynomial kernel as follows: $k(\\mathbf{x}, \\mathbf{y}) = (1 + \\mathbf x^T \\mathbf y)^2$ with $\\mathbf x, \\mathbf y \\in \\mathbb R^2$. The kernel does not seem to correspond to any mapping function $\\varphi$, it's just a function that returns a real number. Our input vectors $\\mathbf{x}, \\mathbf{y}$ are 2-dimensional: $\\mathbf x = (x_1, x_2)$ and $\\mathbf y = (y_1, y_2)$. With this knowledge we can expand the kernel computation:\n",
    "\n",
    "$\\begin{align*}\n",
    "k(\\mathbf x, \\mathbf y) & = (1 + \\mathbf x^T \\mathbf y)^2 \\\\\n",
    "&= (1 + x_1 \\, y_1  + x_2 \\, y_2)^2 \\\\\n",
    " & = 1 + x_1^2 y_1^2 + x_2^2 y_2^2 + 2 x_1 y_1 + 2 x_2 y_2 + 2 x_1 x_2 y_1 y_2\n",
    "\\end{align*}$\n",
    "\n",
    "Note that this is nothing else but a dot product between two vectors $(1, x_1^2, x_2^2, \\sqrt{2} x_1, \\sqrt{2} x_2, \\sqrt{2} x_1 x_2)$ and $(1, y_1^2, y_2^2, \\sqrt{2} y_1, \\sqrt{2} y_2, \\sqrt{2} y_1 y_2)$. This can be expressed with the following mapping function: \n",
    "$$\\varphi(\\mathbf x) = \\varphi(x_1, x_2) = (1, x_1^2, x_2^2, \\sqrt{2} x_1, \\sqrt{2} x_2, \\sqrt{2} x_1 x_2)$$\n",
    "\n",
    "So the kernel $k(\\mathbf x, \\mathbf y) = (1 + \\mathbf x^T \\mathbf y)^2 = \\varphi(\\mathbf x)^T \\varphi(\\mathbf y)$ computes a dot product in 6-dimensional space without explicitly visiting this space. The generalization from an inner product to a kernel function is known as the **kernel trick**.\n",
    "\n",
    "Several popular kernel functions exist. Popular ones are, for example, the [polyomial kernel](https://en.wikipedia.org/wiki/Polynomial_kernel) or [RBF kernel](https://en.wikipedia.org/wiki/Radial_basis_function_kernel)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8.4 Can we also use kernels in the primal SVM? <a class=\"anchor\" id=\"kernel-in-primal-svm\"></a>\n",
    "\n",
    "Yes, the kernel trick can be applied to primal SVM's, too. It's not as straightforward as with dual SVMs but still possible. Consider [this paper by Chapelle et al.](https://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.129.3368&rep=rep1&type=pdf) as an example."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8.5 How do I choose the right kernel for my problem? <a class=\"anchor\" id=\"choosing-the-right-kernel\"></a>\n",
    "\n",
    "The problem of choosing the right kernel has been answered in [this StackExchange post](\n",
    "https://stats.stackexchange.com/questions/18030/how-to-select-kernel-for-svm). \n",
    "\n",
    "Summary:\n",
    "- Without expert knowledge, the Radial Basis Function kernel makes a good default kernel (in case you need a non-linear model)\n",
    "- The choice of the kernel and parameters can be automated by optimising a cross-validation based model selection\n",
    "- Choosing the kernel and parameters automatically is tricky, as it is very easy to overfit the model selection criterion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Sources and further reading <a class=\"anchor\" id=\"sources\"></a>\n",
    "\n",
    "The basis for this notebook is chapter 12 of the book [Mathematics for Machine Learning](https://mml-book.github.io/). I can highly recommend to read through the entire chapter to get a deeper understanding of support vector machines.\n",
    "\n",
    "Another source I liked very much is [this MIT lecture on SVMs](https://www.youtube.com/watch?v=_PwhiWxHK8o)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
